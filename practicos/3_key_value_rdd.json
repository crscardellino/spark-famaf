{"paragraphs":[{"text":"val baseDir=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/03_rdd_notebook\"\nprint(\"\"\"%html\n<center>\n    <h1>Programación Distribuida sobre Grandes Volúmenes de Datos</h1>\n</center>\n\n<br>\n\n<h3 style=\"text-align:center;\">\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    Facultad de Matemática Astronomía Física y Computación\n    </a>\n<br/>\n    <a href=\"http://www.unc.edu.ar\">\n    Universidad Nacional de Córdoba\n    </a>\n<br/>\n    <center>\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    <img src=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/comun/logo%20UNC%20FAMAF%202016.svg\" alt=\"Drawing\" style=\"width:50%;\"/>\n    </a>\n    </center>\n</h3>\n\n<h4 style=\"text-align:center;\"> Damián Barsotti - Ezequiel Orbe </h4>\n\n<p style=\"font-size:15px;\">\n    <br />\n        This work is licensed under a\n        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n        <img alt=\"Creative Commons License\" style=\"border-width:0;vertical-align:middle;float:right\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n    </a>\n</p>\n\"\"\")","dateUpdated":"2016-09-08T03:04:13-0300","config":{"enabled":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","editorHide":true,"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473339853279_1709487897","id":"20160908-150413_562374904","result":{"code":"SUCCESS","type":"HTML","msg":"<center>\n    <h1>Programación Distribuida sobre Grandes Volúmenes de Datos</h1>\n</center>\n\n<br>\n\n<h3 style=\"text-align:center;\">\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    Facultad de Matemática Astronomía Física y Computación\n    </a>\n<br/>\n    <a href=\"http://www.unc.edu.ar\">\n    Universidad Nacional de Córdoba\n    </a>\n<br/>\n    <center>\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    <img src=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/comun/logo%20UNC%20FAMAF%202016.svg\" alt=\"Drawing\" style=\"width:50%;\"/>\n    </a>\n    </center>\n</h3>\n\n<h4 style=\"text-align:center;\"> Damián Barsotti - Ezequiel Orbe </h4>\n\n<p style=\"font-size:15px;\">\n    <br />\n        This work is licensed under a\n        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n        <img alt=\"Creative Commons License\" style=\"border-width:0;vertical-align:middle;float:right\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n    </a>\n</p>\n"},"dateCreated":"2016-09-08T03:04:13-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4252"},{"text":"%md \n###Ejercicio 1\nHacer un programa que calcule las 10 palabras, con mas de 3 caracteres, mas frecuentes en el `README`.","dateUpdated":"2016-09-08T03:04:13-0300","config":{"enabled":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473339853280_1695252188","id":"20160908-150413_836893061","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio 1</h3>\n<p>Hacer un programa que calcule las 10 palabras, con mas de 3 caracteres, mas frecuentes en el <code>README</code>.</p>\n"},"dateCreated":"2016-09-08T03:04:13-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4253"},{"text":"val inputRDD = sc.textFile(\"pruebas/README.md\")\nval words = inputRDD.flatMap(_.split(\" \"))\nval filteredWords = words.filter(_.trim.length > 3)\nval wordCount = filteredWords.map(word => (word, 1)).reduceByKey((x, y) => x + y)\nval result = wordCount.takeOrdered(10)(Ordering[Int].reverse.on (_._2))","dateUpdated":"2016-09-14T08:51:33-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473772770811_1147604009","id":"20160913-151930_44255849","result":{"code":"SUCCESS","type":"TEXT","msg":"inputRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[48] at textFile at <console>:36\nwords: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[49] at flatMap at <console>:38\nfilteredWords: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[50] at filter at <console>:40\nwordCount: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[52] at reduceByKey at <console>:42\nresult: Array[(String, Int)] = Array((package,10), (version,10), (clean,9), (with,8), (Spark,8), (build,7), (sudo,7), (export,7), (#####,6), (profiles,6))\n"},"dateCreated":"2016-09-13T03:19:30-0300","dateStarted":"2016-09-14T08:51:33-0300","dateFinished":"2016-09-14T08:51:34-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4254"},{"text":"%md \n###Ejercicio 2\nDada las siguientes collecciones de pares de elementos:\n\n```\n(\"a\",1),(\"b\",4)\n(\"a\",2),(\"b\",2), (\"c\",5), (\"a\",7)\n(\"a\",2),(\"b\",2), (\"c\",5)\n```\nCalcule la suma total para cada key usando `cogroup`.\n\n```\n(a,12)\n(b,8)\n(c,10)\n```\n\n","dateUpdated":"2016-09-08T03:04:13-0300","config":{"enabled":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473339853280_1695252188","id":"20160908-150413_275671872","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio 2</h3>\n<p>Dada las siguientes collecciones de pares de elementos:</p>\n<pre><code>(\"a\",1),(\"b\",4)\n(\"a\",2),(\"b\",2), (\"c\",5), (\"a\",7)\n(\"a\",2),(\"b\",2), (\"c\",5)\n</code></pre>\n<p>Calcule la suma total para cada key usando <code>cogroup</code>.</p>\n<pre><code>(a,12)\n(b,8)\n(c,10)\n</code></pre>\n"},"dateCreated":"2016-09-08T03:04:13-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4255"},{"text":"val cl1 = sc.parallelize(List((\"a\", 1), (\"b\", 4)))\nval cl2 = sc.parallelize(List((\"a\",2), (\"b\",2), (\"c\",5), (\"a\",7)))\nval cl3 = sc.parallelize(List((\"a\",2), (\"b\",2), (\"c\",5)))\ncl1.cogroup(cl2, cl3).aggregateByKey(0)(\n    (acc, value) => acc + value._1.sum + value._2.sum + value._3.sum,\n    (acc1, acc2) => acc1 + acc2\n).collect","dateUpdated":"2016-09-14T10:15:15-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473879904339_1896880648","id":"20160914-210504_1159786801","result":{"code":"SUCCESS","type":"TEXT","msg":"cl1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[76] at parallelize at <console>:36\ncl2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[77] at parallelize at <console>:36\ncl3: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[78] at parallelize at <console>:36\nres55: Array[(String, Int)] = Array((a,12), (b,8), (c,10))\n"},"dateCreated":"2016-09-14T09:05:04-0300","dateStarted":"2016-09-14T10:15:15-0300","dateFinished":"2016-09-14T10:15:16-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4256"},{"text":"%md \n###Ejercicio 3\nRepita el ejercicio anterior usando `union`","dateUpdated":"2016-09-08T03:04:13-0300","config":{"enabled":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","editorHide":true,"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473339853280_1695252188","id":"20160908-150413_1239475355","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio 3</h3>\n<p>Repita el ejercicio anterior usando <code>union</code></p>\n"},"dateCreated":"2016-09-08T03:04:13-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4257"},{"text":"val cl1 = sc.parallelize(List((\"a\", 1), (\"b\", 4)))\nval cl2 = sc.parallelize(List((\"a\",2), (\"b\",2), (\"c\",5), (\"a\",7)))\nval cl3 = sc.parallelize(List((\"a\",2), (\"b\",2), (\"c\",5)))\ncl1.union(cl2).union(cl3).reduceByKey((x, y) => x + y).collect","dateUpdated":"2016-09-14T10:24:22-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473884610105_1114212131","id":"20160914-222330_1056579457","result":{"code":"SUCCESS","type":"TEXT","msg":"cl1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[93] at parallelize at <console>:36\ncl2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[94] at parallelize at <console>:36\ncl3: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[95] at parallelize at <console>:36\nres61: Array[(String, Int)] = Array((a,12), (b,8), (c,10))\n"},"dateCreated":"2016-09-14T10:23:30-0300","dateStarted":"2016-09-14T10:24:22-0300","dateFinished":"2016-09-14T10:24:23-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4258"},{"text":"%md\n### Ejercicio 4\n\n[DBPedia](http://wiki.dbpedia.org/) es una síntesis estructurada de las relaciones que aparecen en la Wikipedia.\nEstructura sus datos en 2 tipos de archivos:\n* **Propiedades** - Archivo que contiene 3-uplas con (sujeto,relación,predicado), por ejemplo (Aristoteles, Año de nacimiento, -384)\n* **Tipos** - Archivo que contiene 3-uplas con (sujeto, tipo del sujeto, sintaxis de tipo).\n\nEn los *Archivos de prueba* de la materia hay extractos de los mismos (`mappingbased_properties_en.nt` y `instance_types_en.nt`).\n\nAnalizar el formato de estos archivos sanearlos para crear los RDD teniendo en cuenta que:\n* no se pueden modificar a mano los archivos.\n* puede haber lineas basura. Son las que no comienzan con el caracter `<`\n* puede haber lineas en blanco.\n* cada linea termina con un punto que hay que descartar.\n* un sujeto puede aparecer en varias lineas con distintas relacion/predicado en `mappingbased_properties_en.nt`\n* un sujeto puede tener varios tipos en `instance_types_en.nt`.\n* La sintaxis de tipo en el archivo `instance_types_en.nt` no hay que tenerla en cuenta en el algoritmo.\n\nEl programa debe producir una salida que agregue a las propiedades los tipos del sujeto como una lista, de forma tal que cada linea tenga la información de la 4-upla (sujeto, [tipos del sujeto], relación, predicado).\n\n","dateUpdated":"2016-09-08T03:04:13-0300","config":{"enabled":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473339853281_1694867439","id":"20160908-150413_1101715383","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio 4</h3>\n<p><a href=\"http://wiki.dbpedia.org/\">DBPedia</a> es una síntesis estructurada de las relaciones que aparecen en la Wikipedia.\n<br  />Estructura sus datos en 2 tipos de archivos:</p>\n<ul>\n<li><strong>Propiedades</strong> - Archivo que contiene 3-uplas con (sujeto,relación,predicado), por ejemplo (Aristoteles, Año de nacimiento, -384)</li>\n<li><strong>Tipos</strong> - Archivo que contiene 3-uplas con (sujeto, tipo del sujeto, sintaxis de tipo).</li>\n</ul>\n<p>En los <em>Archivos de prueba</em> de la materia hay extractos de los mismos (<code>mappingbased_properties_en.nt</code> y <code>instance_types_en.nt</code>).</p>\n<p>Analizar el formato de estos archivos sanearlos para crear los RDD teniendo en cuenta que:</p>\n<ul>\n<li>no se pueden modificar a mano los archivos.</li>\n<li>puede haber lineas basura. Son las que no comienzan con el caracter <code>&lt;</code></li>\n<li>puede haber lineas en blanco.</li>\n<li>cada linea termina con un punto que hay que descartar.</li>\n<li>un sujeto puede aparecer en varias lineas con distintas relacion/predicado en <code>mappingbased_properties_en.nt</code></li>\n<li>un sujeto puede tener varios tipos en <code>instance_types_en.nt</code>.</li>\n<li>La sintaxis de tipo en el archivo <code>instance_types_en.nt</code> no hay que tenerla en cuenta en el algoritmo.</li>\n</ul>\n<p>El programa debe producir una salida que agregue a las propiedades los tipos del sujeto como una lista, de forma tal que cada linea tenga la información de la 4-upla (sujeto, [tipos del sujeto], relación, predicado).</p>\n"},"dateCreated":"2016-09-08T03:04:13-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4259"},{"text":"val propertiesRDD = sc.textFile(\"bigdata_public/posgrado_optativa/labs/jupiterace/bin/zeppelins/doc/mappingbased_properties_en.nt\")\nval typesRDD = sc.textFile(\"bigdata_public/posgrado_optativa/labs/jupiterace/bin/zeppelins/doc/instance_types_en.nt\")\n\nval validProperties = propertiesRDD.filter(_.startsWith(\"<\"))\nval validTypes = typesRDD.filter(_.startsWith(\"<\"))\n\nval subjectProperties = validProperties.map(l => l.trim.replaceAll(\"\\\\s*.\\\\s*$\", \"\").split(\"\\\\s+\", 3)).map(r => (r(0), (r(1), r(2))))\nval subjectTypes = validTypes.map(l => l.trim.replaceAll(\"\\\\s*.\\\\s*$\", \"\").split(\"\\\\s+\", 3)).map(r => (r(0), r(2))).groupByKey().mapValues(_.toList)\n\nsubjectProperties.leftOuterJoin(subjectTypes).map {\n    case (k, ((r, p), Some(ts))) => (k, ts, r, p)\n    case (k, ((r, p), None)) => (k, Nil, r, p)\n}.collect\n","dateUpdated":"2016-09-20T08:14:41-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1473339853282_1696021686","id":"20160908-150413_2142839766","result":{"code":"SUCCESS","type":"TEXT","msg":"propertiesRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[76] at textFile at <console>:29\ntypesRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[78] at textFile at <console>:29\nvalidProperties: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[79] at filter at <console>:32\nvalidTypes: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[80] at filter at <console>:31\nsubjectProperties: org.apache.spark.rdd.RDD[(String, (String, String))] = MapPartitionsRDD[82] at map at <console>:34\nsubjectTypes: org.apache.spark.rdd.RDD[(String, List[String])] = MapPartitionsRDD[86] at mapValues at <console>:33\nres32: Array[(String, List[String], String, String)] = Array((<http://dbpedia.org/resource/Alp_Arslan>,List(<http://dbpedia.org/ontology/BritishRoyalty>, <http://dbpedia.org/ontology/Royalty>, <http://dbpedia.org/ontology/Person>, <http://wikidata.dbpedia.org/resource/Q5>, <http://xmlns.com/foaf/0.1/Person>, <http://www.w3.org/2002/07/owl#Thing>, <http://schema.org/Person>, <http://wikidata.dbpedia.org/resource/Q215627>, <http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#NaturalPerson>, <http://dbpedia.org/ontology/Agent>, <http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#Agent>),<http://xmlns.com/foaf/0.1/name>,\"Alp Arslan\"@en), (<http://dbpedia.org/resource/Alp_Arslan>,List(<http://dbpedia.org/ontology/BritishRoyalty>, <http://dbpedia.org/ontology/Royalty>, <http://dbpedia.or..."},"dateCreated":"2016-09-08T03:04:13-0300","dateStarted":"2016-09-20T08:14:41-0300","dateFinished":"2016-09-20T08:14:45-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4260"},{"text":"","dateUpdated":"2016-10-12T05:57:18-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474382913937_-1980923080","id":"20160920-164833_1793980301","dateCreated":"2016-09-20T04:48:33-0300","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:4261"}],"name":"Práctico 3 - Key/Value RDD's","id":"2BWBS7FNT","angularObjects":{"2BYHC7ZZP:shared_process":[],"2BYG24GAH:shared_process":[],"2C1K68GVG:shared_process":[],"2BX86U8BP:shared_process":[],"2BZTQXXHY:shared_process":[],"2C12ESVBS:shared_process":[],"2BY2U1RWP:shared_process":[],"2C1QS9EK4:shared_process":[],"2C153FBUS:shared_process":[],"2BXXEMHBZ:shared_process":[],"2BYJQNJU8:shared_process":[],"2BZNV94S8:shared_process":[],"2C1C86E66:shared_process":[],"2BX4CBRP5:shared_process":[],"2C1K19RJJ:shared_process":[],"2BXHZBMPN:shared_process":[],"2C1KJHZ1U:shared_process":[],"2BYJAU465:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}