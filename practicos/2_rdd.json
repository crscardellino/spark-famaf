{"paragraphs":[{"text":"val baseDir=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/practicos/02_rdd\"\nprint(\"\"\"%html\n<center>\n    <h1>Programación Distribuida sobre Grandes Volúmenes de Datos</h1>\n</center>\n\n<br>\n\n<h3 style=\"text-align:center;\">\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    Facultad de Matemática Astronomía Física y Computación\n    </a>\n<br/>\n    <a href=\"http://www.unc.edu.ar\">\n    Universidad Nacional de Córdoba\n    </a>\n<br/>\n    <center>\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    <img src=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/comun/logo%20UNC%20FAMAF%202016.svg\" alt=\"Drawing\" style=\"width:50%;\"/>\n    </a>\n    </center>\n</h3>\n\n<h4 style=\"text-align:center;\"> Damián Barsotti  </h4>\n\n<p style=\"font-size:15px;\">\n    <br />\n        This work is licensed under a\n        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n        <img alt=\"Creative Commons License\" style=\"border-width:0;vertical-align:middle;float:right\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n    </a>\n</p>\n\"\"\")\n","dateUpdated":"2016-08-31T06:04:59-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499564_1550955033","id":"20160831-180459_1340992992","result":{"code":"SUCCESS","type":"HTML","msg":"<center>\n    <h1>Programación Distribuida sobre Grandes Volúmenes de Datos</h1>\n</center>\n\n<br>\n\n<h3 style=\"text-align:center;\">\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    Facultad de Matemática Astronomía Física y Computación\n    </a>\n<br/>\n    <a href=\"http://www.unc.edu.ar\">\n    Universidad Nacional de Córdoba\n    </a>\n<br/>\n    <center>\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    <img src=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/comun/logo%20UNC%20FAMAF%202016.svg\" alt=\"Drawing\" style=\"width:50%;\"/>\n    </a>\n    </center>\n</h3>\n\n<h4 style=\"text-align:center;\"> Damián Barsotti  </h4>\n\n<p style=\"font-size:15px;\">\n    <br />\n        This work is licensed under a\n        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n        <img alt=\"Creative Commons License\" style=\"border-width:0;vertical-align:middle;float:right\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n    </a>\n</p>\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2695"},{"text":"%md\n# Práctico 2\n\n## RDD\n\n**Nota**: Todos los ejercicios deben hacerse utilizando la api Spark/Scala de RDD's.","dateUpdated":"2016-08-31T06:04:59-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499564_1550955033","id":"20160831-180459_268760922","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Práctico 2</h1>\n<h2>RDD</h2>\n<p><strong>Nota</strong>: Todos los ejercicios deben hacerse utilizando la api Spark/Scala de RDD's.</p>\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2696"},{"text":"%md\n### Ejercicio ~\n\nEn la presentación de rdd se mostró un programa que filtra las apariciones de las palabras \"config\" y \"status\":\n```\nval inputRDD = sc.textFile(\"/doc/log.txt\") // RDD\nval statusRDD = inputRDD.filter(line => line.contains(\"ERROR\")) // se crea un nuevo RDD\nval configRDD = inputRDD.filter(line => line.contains(\"config\")) // se crea un nuevo RDD\nval stOrConfRDD = statusRDD.union(configRDD) \n```\nEsta solución puede ser poco eficiente ya que el archivo se recorre dos veces.\nHacer un programa que recorra el archivo solo una vez filtrando ambas apariciones al mismo tiempo.","dateUpdated":"2016-08-31T06:05:54-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499564_1550955033","id":"20160831-180459_450088046","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio ~</h3>\n<p>En la presentación de rdd se mostró un programa que filtra las apariciones de las palabras &ldquo;config&rdquo; y &ldquo;status&rdquo;:</p>\n<pre><code>val inputRDD = sc.textFile(\"/doc/log.txt\") // RDD\nval statusRDD = inputRDD.filter(line =&gt; line.contains(\"ERROR\")) // se crea un nuevo RDD\nval configRDD = inputRDD.filter(line =&gt; line.contains(\"config\")) // se crea un nuevo RDD\nval stOrConfRDD = statusRDD.union(configRDD) \n</code></pre>\n<p>Esta solución puede ser poco eficiente ya que el archivo se recorre dos veces.\n<br  />Hacer un programa que recorra el archivo solo una vez filtrando ambas apariciones al mismo tiempo.</p>\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2697"},{"text":"val inputRDD = sc.textFile(\"log.txt\")\nval stOrConfRDD = inputRDD.filter(line => line.contains(\"ERROR\") || line.contains(\"config\"))\nstOrConfRDD.take(10).foreach(println)","dateUpdated":"2016-08-31T06:08:20-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677587208_-253243118","id":"20160831-180627_854540145","result":{"code":"SUCCESS","type":"TEXT","msg":"inputRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[47] at textFile at <console>:29\nstOrConfRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[48] at filter at <console>:31\n[     5.422] Markers: (--) probed, (**) from config file, (==) default setting,\n\t(WARN) warning, (ERROR) error, (NI) not implemented, (??) unknown.\n[     5.423] (==) Using system config directory \"/usr/share/X11/xorg.conf.d\"\n\tUsing a default monitor configuration.\n\tIf no devices become available, reconfigure udev or disable AutoAddDevices.\n[     5.426] (==) Matched intel as autoconfigured driver 0\n[     5.426] (==) Matched vesa as autoconfigured driver 1\n[     5.426] (==) Matched fbdev as autoconfigured driver 2\n[     5.812] (INFO) config/udev: Adding input device Power Button (/dev/input/event2)\n[     5.813] (**) Option \"config_info\" \"udev:/sys/devices/LNXSYSTM:00/LNXPWRBN:00/input/input2/event2\"\n"},"dateCreated":"2016-08-31T06:06:27-0300","dateStarted":"2016-08-31T06:08:20-0300","dateFinished":"2016-08-31T06:08:20-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2698"},{"text":"%md\n### Ejercicio ~\n\nHacer un programa que cuente las palabras del archivo `README.md`.\n","dateUpdated":"2016-08-31T06:04:59-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499564_1550955033","id":"20160831-180459_1807258300","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio ~</h3>\n<p>Hacer un programa que cuente las palabras del archivo <code>README.md</code>.</p>\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2699"},{"text":"val inputRDD = sc.textFile(\"README.md\")\nval wordsInLineRDD = inputRDD.flatMap(line => line.split(\"\\\\s+\"))\nval wordsInFile = wordsInLineRDD.count","dateUpdated":"2016-08-31T06:16:53-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677716964_1960818236","id":"20160831-180836_2124515231","result":{"code":"SUCCESS","type":"TEXT","msg":"inputRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[62] at textFile at <console>:29\nwordsInLineRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[63] at flatMap at <console>:31\nwordsInFile: Long = 827\n"},"dateCreated":"2016-08-31T06:08:36-0300","dateStarted":"2016-08-31T06:16:53-0300","dateFinished":"2016-08-31T06:16:54-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2700"},{"text":"%md\n### Ejercicio ~\n\nImplementar la acción `count` solo con la acción `aggregate`. Hacer algunas pruebas con el programa.    \n","dateUpdated":"2016-08-31T06:04:59-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499564_1550955033","id":"20160831-180459_1260056774","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio ~</h3>\n<p>Implementar la acción <code>count</code> solo con la acción <code>aggregate</code>. Hacer algunas pruebas con el programa.</p>\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2701"},{"text":"val inputRDD = sc.textFile(\"README.md\")\nval wordsInLineRDD = inputRDD.flatMap(line => line.split(\"\\\\s+\"))\nval wordsInFile = wordsInLineRDD.aggregate(0)((acc, value) => acc + 1, (acc1, acc2) => acc1 + acc2)","dateUpdated":"2016-08-31T06:21:53-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472678356354_-1881400296","id":"20160831-181916_673323770","result":{"code":"SUCCESS","type":"TEXT","msg":"inputRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[68] at textFile at <console>:29\nwordsInLineRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[69] at flatMap at <console>:31\nwordsInFile: Int = 827\n"},"dateCreated":"2016-08-31T06:19:16-0300","dateStarted":"2016-08-31T06:21:53-0300","dateFinished":"2016-08-31T06:21:54-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2702"},{"text":"%md\n###Ejercicio ~\nContar la cantidad de veces que aparece la letra 'c' en el archivo `README.md` utilizando la transformación `flatMap`.","dateUpdated":"2016-08-31T06:04:59-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499565_1550570284","id":"20160831-180459_2081644760","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio ~</h3>\n<p>Contar la cantidad de veces que aparece la letra 'c' en el archivo <code>README.md</code> utilizando la transformación <code>flatMap</code>.</p>\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2703"},{"text":"val inputRDD = sc.textFile(\"README.md\")\nval letterCRDD = inputRDD.flatMap(line => line.split(\"\").filter(_ == \"c\"))\nval countCLetter = letterCRDD.count","dateUpdated":"2016-08-31T06:26:44-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472678540327_-123388981","id":"20160831-182220_1908472560","result":{"code":"SUCCESS","type":"TEXT","msg":"inputRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[75] at textFile at <console>:29\nletterCRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[76] at flatMap at <console>:31\ncountCLetter: Long = 158\n"},"dateCreated":"2016-08-31T06:22:20-0300","dateStarted":"2016-08-31T06:26:44-0300","dateFinished":"2016-08-31T06:26:44-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2704"},{"text":"%md\n###Ejercicio ~\n\nDevolver todos los links internos del archivo `wikipedia_short.xml` (el archivo esta en el la página de la materia o en el directorio `/doc`).\nPueden aparecer varios links en una lines y son de la forma `[[link]]` o `[[link|text]]`.\n**Ayuda**: ver [información sobre expresiones regulares en Scala](https://www.safaribooksonline.com/library/view/scala-cookbook/9781449340292/ch01s07.html).","dateUpdated":"2016-08-31T06:04:59-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499565_1550570284","id":"20160831-180459_2024240008","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio ~</h3>\n<p>Devolver todos los links internos del archivo <code>wikipedia_short.xml</code> (el archivo esta en el la página de la materia o en el directorio <code>/doc</code>).\n<br  />Pueden aparecer varios links en una lines y son de la forma <code>[[link]]</code> o <code>[[link|text]]</code>.\n<br  /><strong>Ayuda</strong>: ver <a href=\"https://www.safaribooksonline.com/library/view/scala-cookbook/9781449340292/ch01s07.html\">información sobre expresiones regulares en Scala</a>.</p>\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2705"},{"text":"val inputRDD = sc.textFile(\"pruebas/wikipedia_short.xml\")\nval linksRDD = inputRDD.flatMap(line => \"\"\"\\[\\[([ ^\\] ])+\\]\\]\"\"\".r.findAllIn(line)).collect","dateUpdated":"2016-09-13T02:52:24-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472678785449_1459219518","id":"20160831-182625_2015264299","result":{"code":"SUCCESS","type":"TEXT","msg":"inputRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[3] at textFile at <console>:29\nlinksRDD: Array[String] = Array([[WP:RCAT|rcat]], [[Computer accessibility]], [[political philosophy]], [[self-governance|self-governed]], [[stateless society|stateless societies]], [[Hierarchy|hierarchical]], [[Free association (communism and anarchism)|free associations]], [[Peter Kropotkin]], [[An Anarchist FAQ]], [[state (polity)|state]], [[The Globe and Mail]], [[Routledge Encyclopedia of Philosophy]], [[anti-statism]], [[authority]], [[hierarchical organisation]], [[International of Anarchist Federations]], [[Murray Bookchin]], [[Emma Goldman]], [[Anarchism and Other Essays]], [[Benjamin Tucker]], [[George Woodcock]], [[Mikhail Bakunin]], [[Anarchist schools of thought]], [[individualism]], [[social anarchism|social]], [[individualist anarchism]], [[Geoffrey Ostergaard|Ostergaard,..."},"dateCreated":"2016-08-31T06:26:25-0300","dateStarted":"2016-09-08T05:20:35-0300","dateFinished":"2016-09-08T05:20:38-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2706"},{"text":"%md\n### Ejercicio ~\n\nDado el archivo `wikipedia_short.xml` contar las cantidad de lineas que tienen la palabra \"human\", las que tienen la palabra \"activity\" y las que tienen ambas palabras. Puede suponer que no hay lineas repetidas.\nProbar hacer el programa sin y con persistencia en memoria y comparar los resultados utilizando *Spark UI*.","dateUpdated":"2016-08-31T06:04:59-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499565_1550570284","id":"20160831-180459_1462055762","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Ejercicio ~</h3>\n<p>Dado el archivo <code>wikipedia_short.xml</code> contar las cantidad de lineas que tienen la palabra &ldquo;human&rdquo;, las que tienen la palabra &ldquo;activity&rdquo; y las que tienen ambas palabras. Puede suponer que no hay lineas repetidas.\n<br  />Probar hacer el programa sin y con persistencia en memoria y comparar los resultados utilizando <em>Spark UI</em>.</p>\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2707"},{"text":"val inputRDD = sc.textFile(\"pruebas/wikipedia_short.xml\")\nval human_and_activityRDD = inputRDD.filter(line => (line contains \"human\") && (line contains \"activity\")).count()\nval humanRDD = inputRDD.filter(line => line contains \"human\").count()\nval activityRDD = inputRDD.filter(line => line contains \"activity\").count()","dateUpdated":"2016-09-13T03:14:22-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499565_1550570284","id":"20160831-180459_743950764","result":{"code":"SUCCESS","type":"TEXT","msg":"inputRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[3] at textFile at <console>:29\nhuman_and_activityRDD: Long = 5\nhumanRDD: Long = 15\nactivityRDD: Long = 12\n"},"dateCreated":"2016-08-31T06:04:59-0300","dateStarted":"2016-09-13T03:14:22-0300","dateFinished":"2016-09-13T03:14:25-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2708"},{"title":"FIN","text":"println(\"\"\"%html\n<script>\n    var heads = document.getElementsByTagName('h3');\n    var numHeads = heads.length;\n    var inner = \"\";\n    var i = 0;\n    var j = 0;\n    while (i < numHeads){\n        inner = heads[i].innerHTML;\n        if (inner.search(\"Ejercicio\") != -1 ) {\n            j++;\n            heads[i].innerHTML = inner.replace(/Ejercicio (~|\\d+)/,\"Ejercicio \"+j);\n        }\n        i++\n    }\n</script>\n\"\"\")","dateUpdated":"2016-08-31T06:04:59-0300","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","title":true,"editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1472677499565_1550570284","id":"20160831-180459_1260742064","result":{"code":"SUCCESS","type":"HTML","msg":"<script>\n    var heads = document.getElementsByTagName('h3');\n    var numHeads = heads.length;\n    var inner = \"\";\n    var i = 0;\n    var j = 0;\n    while (i < numHeads){\n        inner = heads[i].innerHTML;\n        if (inner.search(\"Ejercicio\") != -1 ) {\n            j++;\n            heads[i].innerHTML = inner.replace(/Ejercicio (~|\\d+)/,\"Ejercicio \"+j);\n        }\n        i++\n    }\n</script>\n\n"},"dateCreated":"2016-08-31T06:04:59-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2709"}],"name":"Práctico 2 - RDD","id":"2BTW81MB6","angularObjects":{"2BVNPSW9V":[],"2BTMC7TKA":[],"2BSRRZ7M4":[],"2BSVVSEN7":[],"2BV1K682G":[],"2BVTN1H7Q":[],"2BVCFHS2D":[],"2BWBXGZP1":[],"2BSWUK1NJ":[],"2BUNT31B1":[],"2BTYA3GWQ":[],"2BW6STQAT":[],"2BVMB1STV":[],"2BV59N5AU":[]},"config":{"looknfeel":"default"},"info":{}}